# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pE-B7eW7jpR8X9kKKEAwdoC7UvrhmGmW
"""

import os
import torch
import numpy as np
from transformers import (
    AutoTokenizer,
    LEDForConditionalGeneration,
    DataCollatorForSeq2Seq,
    Seq2SeqTrainingArguments,
    Seq2SeqTrainer,
)
from config import MODEL_CHECKPOINT, OUTPUT_DIR, LOGGING_DIR
from dataset import load_dataset
from model_utils import compute_metrics, LossPrinterCallback

os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

def main():

    tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)
    tokenized_datasets, raw_ds = load_dataset(tokenizer)

    model = LEDForConditionalGeneration.from_pretrained(MODEL_CHECKPOINT)

    data_collator = DataCollatorForSeq2Seq(
        tokenizer,
        model=model,
        label_pad_token_id=-100,
    )

    training_args = Seq2SeqTrainingArguments(
        output_dir=OUTPUT_DIR,
        num_train_epochs=3,
        per_device_train_batch_size=1,
        gradient_accumulation_steps=8,
        gradient_checkpointing=True,
        per_device_eval_batch_size=4,
        warmup_steps=500,
        weight_decay=0.01,
        logging_dir=LOGGING_DIR,
        logging_strategy="steps",
        logging_steps=5,
        eval_strategy="epoch",
        save_strategy="epoch",
        load_best_model_at_end=True,
        fp16=False,
        report_to="none",
        save_total_limit=3,
        predict_with_generate=True,
        generation_max_length=256,
    )

    trainer = Seq2SeqTrainer(
        model=model,
        args=training_args,
        train_dataset=tokenized_datasets["train"],
        eval_dataset=tokenized_datasets["validation"],
        tokenizer=tokenizer,
        data_collator=data_collator,
        compute_metrics=lambda pred: compute_metrics(pred, tokenizer),
        callbacks=[LossPrinterCallback()],
    )

    print("Starting training...")
    trainer.train()

    trainer.save_model(OUTPUT_DIR)
    tokenizer.save_pretrained(OUTPUT_DIR)

    print("Testing model...")
    test_results = trainer.evaluate(tokenized_datasets["test"])
    print(test_results)


if __name__ == "__main__":
    main()